#CDH comes prepackaged with a log generating job. start_logs, stop_logs and tail_logs. Using these as an aid and provide a solution to below problem. The generated logs can be found at path /opt/gen_logs/logs/access.log  
#run start_logs
#write a flume configuration such that the logs generated by start_logs are dumped into HDFS at location /user/cloudera/problem7/step2. The channel should be non-durable and hence fastest in nature. The channel should be able to hold a maximum of 1000 messages and should commit after every 200 messages. 
#Run the agent. 
#confirm if logs are getting dumped to hdfs.  
#run stop_logs.




# Name the components on this agent
eatlog.sources = r1
eatlog.sinks = k1
eatlog.channels = c1

# Describe/configure the source
eatlog.sources.r1.type = exec
eatlog.sources.r1.command = tail -F /opt/gen_logs/logs/access.log


# Describe the sink
eatlog.sinks.k1.type = hdfs
eatlog.sinks.k1.hdfs.path = /user/cloudera/problem7/step2

# Use a channel which buffers events in memory
eatlog.channels.c1.type = memory
eatlog.channels.c1.capacity = 1000
eatlog.channels.c1.transactionCapacity = 200

# Bind the source and sink to the channel
eatlog.sources.r1.channels = c1
eatlog.sinks.k1.channel = c1


